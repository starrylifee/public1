import streamlit as st
import requests
from PIL import Image
import io
import random
import google.generativeai as genai
from openai import OpenAI

# í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ì •
st.set_page_config(layout="wide")

# API í‚¤ ë¦¬ìŠ¤íŠ¸
api_keys = [
    st.secrets["api_key1"],
    st.secrets["api_key2"],
    st.secrets["api_key3"],
    st.secrets["api_key4"],
    st.secrets["api_key5"],
    st.secrets["api_key6"],
    st.secrets["api_key7"],
    st.secrets["api_key8"],
    st.secrets["api_key9"],
    st.secrets["api_key10"],
    st.secrets["api_key11"],
    st.secrets["api_key12"]
]

# ëœë¤í•˜ê²Œ API í‚¤ ì„ íƒ
selected_api_key = random.choice(api_keys)
client = OpenAI(api_key=selected_api_key)

# Google Generative AI ì„¤ì •
genai_api_keys = [
    st.secrets["gemini_api_key1"],
    st.secrets["gemini_api_key2"],
    st.secrets["gemini_api_key3"],
    st.secrets["gemini_api_key4"],
    st.secrets["gemini_api_key5"],
    st.secrets["gemini_api_key6"],
    st.secrets["gemini_api_key7"],
    st.secrets["gemini_api_key8"],
    st.secrets["gemini_api_key9"],
    st.secrets["gemini_api_key10"],
    st.secrets["gemini_api_key11"],
    st.secrets["gemini_api_key12"]
]

selected_genai_api_key = random.choice(genai_api_keys)
genai.configure(api_key=selected_genai_api_key)

# ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì²˜ë¦¬
uploaded_file = st.file_uploader("ğŸ“± í•¸ë“œí° ì‚¬ì§„ ì—…ë¡œë“œ")

# í•™ìƒì´ ë„£ê³  ì‹¶ì€ ë¬˜ì‚¬ ì…ë ¥ë°›ê¸°
student_description = st.text_input("í•™ìƒì´ ì¶”ê°€í•˜ê³  ì‹¶ì€ ë¬˜ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "")

# ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
if uploaded_file is not None:
    img_bytes = uploaded_file.read()
    img = Image.open(io.BytesIO(img_bytes))
    st.image(img, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")

    if st.button("ë¬˜ì‚¬ ìƒì„± ë° ìºë¦¬ì»¤ì³ ìƒì„±"):
        try:
            # Google Generative AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¬˜ì‚¬ ìƒì„±
            model = genai.GenerativeModel('gemini-pro-vision')
            response = model.generate_content([
                "ì´ ì‚¬ì§„ì„ ìì„¸íˆ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”. ì„±ë³„, í—¤ì–´ìŠ¤íƒ€ì¼, ëˆˆì½”ì…, ì˜·, ì•…ì„¸ì„œë¦¬, í‘œì •, í”¼ë¶€ìƒ‰, ì–¼êµ´í˜•, ë‚˜ì´, ë¨¸ë¦¬ì¹´ë½ ê¸¸ì´, ëˆˆìƒ‰ê¹”, ë¨¸ë¦¬ìƒ‰ê¹” ë“±ì„ ìì„¸í•œ í‘œí˜„ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.", 
                img
            ])
            response.resolve()
            ai_description = response.text
            st.write("AIê°€ ìƒì„±í•œ ì´ë¯¸ì§€ ë¬˜ì‚¬: ", ai_description)
            st.write("ì˜¤ë¥¸ìª½ ìœ„ 'Running'ì´ ì—†ì–´ì§ˆ ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”")
            # ìµœì¢… ë¬˜ì‚¬ ìƒì„±
            final_description = f"{ai_description}. í•™ìƒì´ ì¶”ê°€í•œ ë¬˜ì‚¬: {student_description}"
            st.write("ìµœì¢… ë¬˜ì‚¬: ", final_description)

            # OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
            image_response = client.images.generate(
                model="dall-e-3",
                prompt=f"Caricature of the person: {final_description}",
                size="1024x1024",
                quality="standard",
                n=1
            )

            # ìƒì„±ëœ ì´ë¯¸ì§€ í‘œì‹œ
            generated_image_url = image_response.data[0].url
            st.image(generated_image_url, caption="ìƒì„±ëœ ìºë¦¬ì»¤ì³")

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„
            response = requests.get(generated_image_url)
            image_bytes = io.BytesIO(response.content)

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.download_button(label="ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
                               data=image_bytes,
                               file_name="caricature.jpg",
                               mime="image/jpeg")
        except Exception as e:
            st.error(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
else:
    st.markdown("ğŸ“± í•¸ë“œí° ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
